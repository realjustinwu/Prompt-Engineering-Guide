# 杂项议题

在本节中，我们讨论了提示工程中的其他杂项和未分类的主题。它包括相对较新的想法和方法，当它们被更广泛地采用时，最终会被移到主要指南中。指南的这一部分对于了解提示工程的最新研究论文也很有用。

**请注意，这部分内容正在大力开发中**。

主题：
- [主动提示](#主动提示)
- [定向刺激提示](#定向刺激提示)
- [ReAct](#react)
- [多模态CoT提示](#多模态CoT提示)
- [图形提示](#图形提示)
- ...

---

## 主动提示

思维链（CoT）方法依赖于一组固定的人类注释的范例。这样做的问题是，这些范例对于不同的任务来说可能不是最有效的范例。为了解决这个问题，[Diao等人，(2023)](https://arxiv.org/pdf/2302.12246.pdf)最近提出了一种新的提示方法，称为Active-Prompt，以使LLM适应不同任务的特定范例提示（用人类设计的CoT推理来注释）。

下面是该方法的一个说明。第一步是用或不用几个CoT例子来查询LLM。为一组训练问题生成*k*可能的答案。根据*k*的答案计算出不确定性指标（使用的是分歧）。最不确定的问题被挑选出来由人类进行注释。然后，新的注释典范被用来推断每个问题。

![](./img/active-prompt.png)

---
## 定向刺激提示
[Li et al., (2023)](https://arxiv.org/abs/2302.11520)提出了一种新的提示技术，以更好地指导LLM生成所需的摘要。

一个可调整的策略LM被训练来产生刺激/提示。看到了更多使用RL来优化LLM的情况。

下图显示了定向刺激提示与标准提示的比较。政策LM可以是小的，优化后可以产生指导黑盒冻结LLM的提示。

![](./img/dsp.jpeg)

完整的例子即将到来!

---
## ReAct

[Yao et al., 2022](https://arxiv.org/abs/2210.03629)介绍了一个框架，其中LLM被用来以交错的方式生成推理痕迹和特定任务行动。生成推理跟踪允许模型诱导、跟踪和更新行动计划，甚至处理异常。行动步骤允许与外部资源（如知识库或环境）对接并收集信息。

ReAct框架可以让LLM与外部工具互动，以检索更多的信息，从而获得更可靠的、符合事实的反应。

![](./img/react.png)

完整的例子即将推出!

---
## 多模态CoT提示

[Zhang et al. (2023)](https://arxiv.org/abs/2302.00923)最近提出了一种多模态的思维链提示方法。传统的CoT着重于语言模式。相比之下，多模态CoT将文本和视觉纳入一个两阶段的框架。第一步涉及基于多模态信息的理由生成。接下来是第二阶段，即答案推理，它利用了信息生成的理由。

多模态CoT模型（1B）在ScienceQA基准上的表现超过了GPT-3.5。

![](./img/multimodal-cot.png)

进一步阅读：
- [Language Is Not All You Need: Aligning Perception with Language Models](https://arxiv.org/abs/2302.14045) (Feb 2023)

---
## 图形提示

[Liu et al., 2023](https://arxiv.org/abs/2302.08043)介绍了GraphPrompt，这是一个新的图形提示框架，用于提高下游任务的性能。

更多内容即将推出!

---
[上一节（可靠性）](./prompts-reliability.md)